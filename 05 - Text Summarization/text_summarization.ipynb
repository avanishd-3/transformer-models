{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train summarization model"
      ],
      "metadata": {
        "id": "kTQoI1_WQ6l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets\n",
        "\n",
        "%pip install py7zr # For samsum dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Hf3RpvRJyf",
        "outputId": "183fdfc4-d45d-4dfb-b1fb-ac78a6792748"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting texttable (from py7zr)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr)\n",
            "  Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n",
            "  Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr) (5.9.5)\n",
            "Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed brotli-1.1.0 inflate64-1.0.1 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.3 pycryptodomex-3.22.0 pyppmd-1.1.1 pyzstd-0.16.2 texttable-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Look at Dataset\n",
        "\n",
        "Using SAMsum dataset (collection of dialogues with summaries)"
      ],
      "metadata": {
        "id": "Nlj-61-7RBb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "samsum_dataset = load_dataset(\"samsum\") # Probably shouldn't just do trust remote code\n",
        "\n",
        "# Look at dialogue\n",
        "print(\"Dialogue: \")\n",
        "print(samsum_dataset[\"test\"][0][\"dialogue\"])\n",
        "\n",
        "# Look at summary\n",
        "print(\"\\nSummary: \")\n",
        "print(samsum_dataset[\"test\"][0][\"summary\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756,
          "referenced_widgets": [
            "0c80ba4e2a944fd983bd4df6d5730be2",
            "6b01c68a5555400db300fced8a252959",
            "97714ffa419d402c945146a983b52037",
            "f00ef0344ece408c9bc2476853992bfa",
            "fe92b90c0818463981665a6a9f4b0c27",
            "5545200622d74cb2b212951af6b9e71a",
            "579aaa5e48fb408882d831d0a1709334",
            "d2aad141fb274bacbbab3130a9389565",
            "1a895aa290874b44a028a7190d757e84",
            "f17bf8fb3c76407e9bd31c39b5dca1e9",
            "994fc7e20ce342b082cf7f42210f1152",
            "e29007f0c62f48e8b76fd0f82dd76369",
            "22bd8be1de37421cbcea1d920e376e88",
            "9c023018412349dca12bfb93476d925f",
            "bd90a493a6374783ad7b0936e8030d29",
            "17124f5b8665495c81f61a3f95be9d78",
            "d81d5a3f45d5444ea415d57ee4a20c52",
            "cc7da391aae74e5fbd45e504e852489d",
            "c2538a986df24f7a9755daf61338c4d3",
            "843156bade2443568f5941fd3367b0d8",
            "9076b0d9ed5d42e9bee3a218d9d90c3f",
            "c398417ebd2541ac8bee457a21860687",
            "43fa067178684659bfa8ed5ce274cab9",
            "84c53f557a0a4c8fa7dd040c42087b31",
            "d0361f234c7f420fa2d67eee6a238d3a",
            "3b73671a4afe4a049129c7ab3dd34c6c",
            "c752202ab3e748058120b3fe671ed6fc",
            "3a3c8b35ee45434b9b8481b1e8971174",
            "b3e4ab06a7024a69ae61845b2a193fa5",
            "5a7a8e77e2634efd94771ee601eb8c60",
            "710f0fb23a7241cea97d74f946386230",
            "e98d32f443104c99ba6cd405374604f4",
            "38ccf90f5fbf472c845457be0ef245e8",
            "d11080c60afe47b7b061f9c648df981c",
            "d89bc73d993644e0abd8bada8a254545",
            "13590552bd4c4b848ef460f03d33b84c",
            "dbc4f005600d430aac86ba67df147112",
            "b91c4a81c57a435c9236b8f54788e9c2",
            "7e9f083ad27641ebb39f5f527a5dfad9",
            "b8feccb8525d455e85f843db8771cc2c",
            "cfeaf7cc676940a2ae4faf4025eb5ebb",
            "4d7dad4376c140a8810e23f25b756019",
            "7cf78a1ee666488c8c26ba6689e94fb6",
            "e52d529489c14220bd13bf6db5ee02bf",
            "2f844e5cf6e14e44871d6ad9cadd5b24",
            "30ab6cdf605b4aa1b7384022e49b4c72",
            "904c3416df0147318944e6a27fefe083",
            "adf61dc6070644aab9696e4dcc7ad82a",
            "8d80ba1623fb4e2da40ea5f01b2ac998",
            "844c7f9d55064618876fbcf78a809784",
            "7b35c81cdc454075959aa9343481560e",
            "8506b63faccf4c32baf3203711dfdc03",
            "177ab168ef6a4f10a201b40b972a4fb2",
            "84ca0b49231b454bb45d7bf3d03d1531",
            "310dd39565eb47f198d8abf99cf497c5",
            "cf0e1662bf9e4d0f8a5ac5997160d01a",
            "98bc03bb3d184d3c85b30e1bedcdd1f6",
            "8d100e374ef848e89caf8a6253c2f31e",
            "eb1ebd2737cc43ccb6cb4c5f863934f7",
            "442d0a1a73d04515af306ab5edfd83dc",
            "3b7eebf3ec954ba7b841e22e8f17fb12",
            "327b023978854d17ba4c2cd4fa2694e0",
            "7e69d0092b53481bbcc71b415f2097d4",
            "65ca657ef4624cb5a65efd09ccfb83fb",
            "e39653ab355d4403a211f078f7e43c46",
            "16c5e7ce33094a5094b953b59ffe6da0"
          ]
        },
        "id": "ZJmYCI-gRAlY",
        "outputId": "6a04a372-a3b4-45c7-fd5b-a83c78a2217b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c80ba4e2a944fd983bd4df6d5730be2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "samsum.py:   0%|          | 0.00/3.36k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e29007f0c62f48e8b76fd0f82dd76369"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for samsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/samsum.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "corpus.7z:   0%|          | 0.00/2.94M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43fa067178684659bfa8ed5ce274cab9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d11080c60afe47b7b061f9c648df981c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f844e5cf6e14e44871d6ad9cadd5b24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf0e1662bf9e4d0f8a5ac5997160d01a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue: \n",
            "Hannah: Hey, do you have Betty's number?\n",
            "Amanda: Lemme check\n",
            "Hannah: <file_gif>\n",
            "Amanda: Sorry, can't find it.\n",
            "Amanda: Ask Larry\n",
            "Amanda: He called her last time we were at the park together\n",
            "Hannah: I don't know him well\n",
            "Hannah: <file_gif>\n",
            "Amanda: Don't be shy, he's very nice\n",
            "Hannah: If you say so..\n",
            "Hannah: I'd rather you texted him\n",
            "Amanda: Just text him 🙂\n",
            "Hannah: Urgh.. Alright\n",
            "Hannah: Bye\n",
            "Amanda: Bye bye\n",
            "\n",
            "Summary: \n",
            "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get PEGASUS model"
      ],
      "metadata": {
        "id": "qa3NO12pSrN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"google/pegasus-cnn_dailymail\"\n",
        "\n",
        "pegagus_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297,
          "referenced_widgets": [
            "b78bae81a4db477983d82a57804022a7",
            "b65ab3f865b34c3e8065416067ffb11b",
            "e6411321a75a4b3b849584cf5d5256e7",
            "2f7085c18b6e4da9b8e5ae19dd289455",
            "4434bfcb73ad4d04951b4a563488bd19",
            "ca207b92a8c64c378c38d071941cea70",
            "1fc5d42fbcaa42b183196f837c811d00",
            "9f5ba0a22a0444c8ac2602e2e0bd3863",
            "ba1b8f98f9e94ebfb9eef73224e0e0a4",
            "c885062d6d61486cbf1f9339fcc9da63",
            "010b09c263d0481d9da433adf313fd2b",
            "058f587ccf6b48438e9e3147d54a518f",
            "b2e4e4bbbb144c6c87102217b8d03811",
            "1a6a71024c2849a7a85dd21d0b3493f1",
            "18ca4df018934be6a57f1891dcf0a1f8",
            "d9bb17a547f14203b8dfd082430f5f35",
            "2a7146e4beae4e9794e9c62100cefe5e",
            "4a92178e885b4560b137a858846e06dd",
            "d8adddb8c1d545279b10a97c413af8b8",
            "5b18061d9b4e48dd90e1ce6a4a41e71f",
            "d9e6738157a7402f8884001e41b8d15d",
            "68af6b22370c4fb6b4961f039a75d887",
            "06ccdf73cc2a48b98d46d0cf25b1f7a9",
            "16c09032d73545adb3f6a36d7e20cad3",
            "af3a724d4be0486e96bbca185ad416be",
            "075ec31bd5814e768d72fbbf06cb006d",
            "6f3563f976b344dbaca207f5bb389079",
            "4bad2e0cd866446987346d4c9320ee34",
            "7fed39d2fb6d48ac87cdec3c3468d98d",
            "c06a1f342982443290dd3f8900837451",
            "e3e863a8c9054a05894ada5ac3e0a661",
            "e259b1f2a3a7456486440d3b270dc3e1",
            "85e87a6745374f66b35958683402cd4d",
            "a7e130a4ad1749a3b72f0f9e4450867e",
            "ab1a53a682ff40a19b1f34760fbe92c5",
            "a02df94bb73a4fa292e689742fc08016",
            "16f6cb3f6fd5402b99cb66364dcd91a6",
            "c0d77c7d428c4a9db85e974023e99e94",
            "ce4b2ced55274f72ba8fbca28d41494d",
            "d840083be6ec4ee2ac0588672977917a",
            "f8fec1e8276541a8ab0563e7c215035e",
            "a0119bbb01a74cec901b438ba9220532",
            "c596a2190af04275a7957b2cd7f0e283",
            "0617e64ce82f4b7a993246ad7a3f4d5a",
            "fc660c25f5ff43a0b708eb675ed0ffd5",
            "f1b8c541a2334d589ff6f9fc679411a9",
            "80b90913faa3472698a855eec4966ae0",
            "f2f9e4dcc7ca48018b3a1acd231a36d1",
            "a9f5c09dbde74f039b4e7c45d6ab8eac",
            "5576821e317d447f8789d50dfedfcad7",
            "5ffd206e1a034350a56a556b2abd252e",
            "13aeb9bd3e764ca5b4202e3c249c5bcd",
            "74ca5a34f2e246cba0888797153388ca",
            "1c5c0283b4df4493bf06fe76cd17f938",
            "38f6a0f68ebc4226a07b264187f49a14",
            "e18ae2c31d1b47078590dea0581dad17",
            "b95ce7fcce89419dbd116bd8076fe04e",
            "08910f3aa5814dfda02a748923e7f378",
            "0df4ee7ac55d4956bc9495dd51895497",
            "f9e29aaa4e3f446495b524499ae06e46",
            "e16d1cb71ced44229a0ea2654c2ec971",
            "94d8740cf33a40b2b86e703a2d3142ba",
            "80f1357e7e0e4b2ab7c584910c8a4690",
            "4e75daf9b0504c4e94b2a53c3d530a44",
            "74f078190f3b4f5f820781d7e14284fd",
            "cb9ea1c107264ef08e7cbacd28e12cc0",
            "60b3cda2e1b242d49ea82f58e3a17025",
            "eaa271b36e124cd4bb1720f37101914f",
            "131d22d5839c41e5903704b339652979",
            "85007d480e7b43229a45329d51e7aac3",
            "25eb91ef2f03441bbbf75639ff95fde8",
            "dccd2c4004304213b847bc808a9f5f84",
            "ca9b66069bfe4c38852395c4e3442308",
            "2f937866680446abb14b87442b59597f",
            "a8a652e7b165489baf20ee26b8e006ac",
            "611a4fb8076b4bd5bc95d14a817b6099",
            "b2d2781180a64ce38ef40ec3204ca49f"
          ]
        },
        "id": "7x5Bll5UStDm",
        "outputId": "204b7223-b0ab-4573-87f8-f21103dd0b0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b78bae81a4db477983d82a57804022a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "058f587ccf6b48438e9e3147d54a518f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06ccdf73cc2a48b98d46d0cf25b1f7a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7e130a4ad1749a3b72f0f9e4450867e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc660c25f5ff43a0b708eb675ed0ffd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e18ae2c31d1b47078590dea0581dad17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60b3cda2e1b242d49ea82f58e3a17025"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize Dataset"
      ],
      "metadata": {
        "id": "go6TrYQITDgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def tokenize_dataset(batch):\n",
        "\n",
        "  # Let collator handle padding (seq2se2 collator does dynamic padding)\n",
        "  input_encodings = pegagus_tokenizer(batch[\"dialogue\"], max_length=1024, truncation=True, padding=False)\n",
        "\n",
        "  # Tokenizer knows it is tokenizing for decoder (encoder steps may be different)\n",
        "  target_encodings = pegagus_tokenizer(text_target=batch[\"summary\"], max_length=128, truncation=True, padding=False)\n",
        "\n",
        "  return {\n",
        "      \"input_ids\": input_encodings[\"input_ids\"],\n",
        "      \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "      \"labels\": target_encodings[\"input_ids\"]\n",
        "  }\n",
        "\n",
        "\n",
        "samsum_dataset = samsum_dataset.map(tokenize_dataset, batched=True)\n",
        "\n",
        "columns = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "\n",
        "samsum_dataset.set_format(type=\"torch\", columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7cfbdf0a255b4bd0b0e0b4462e33f18d",
            "94efc56225e64bb6b55800079c7beb7e",
            "b0d3589672a7466ea8a2edc99edfa2c9",
            "c925859fb9a5406184f560f805db2d87",
            "c922ec68f7404598bff9371932536893",
            "c888e0010a5d4efe83b66f2c1c1ca866",
            "c9e60acd6cc2407db46845f2d89c4012",
            "42e9c36078fd4a89a52731fc363071af",
            "c3ac9b21fdbf4865a52d6f58b0d2f38c",
            "5ca91be3d2b34682b37b422775f91dcf",
            "85667d1a9b7142cb9413ecba853bb46b",
            "967373b240ab4b138aaf8c3c41acbbce",
            "3d55eb06caf147c5b71aa52d0c8d4c7c",
            "6b72880aea524a2a81e13d5e03e2bbca",
            "c07ef35d83a340dc9cef47b8adef338c",
            "77f74f08c3d542f5ab0101ce6a97c50e",
            "444078dee3c54fa4be3196877143a18f",
            "bb697a7e0dd54b14b71e425234e54ca3",
            "e9960950f2e643fd92acd224532f4468",
            "ca4cfc151df64e53b6b4c3c386b03179",
            "4db43362f0a2413aa7130e7b7ad0d865",
            "a6671bb5aa8f4046917e6b60af5cd588",
            "a464bde29228401d84a9fa2a5d91837d",
            "af992fd781a0495889c8b8a657e56790",
            "9a93ab7e035d4fd9ac71c1a93b32b660",
            "a38e3c81b5784cc9867c523bde407a96",
            "48837f0d639d47c9b3be0f9d46053335",
            "0eb9ec36b5384068a6241dff2211203f",
            "889812d411d6496c9cae1b53cd43269e",
            "5c743c9d7493488ab3b26572c722446a",
            "18f0559f044049058ec4635b450f7cb1",
            "76a184233e384ee0b61188f559bba1d7",
            "bce14b59679c440ca9dba725a0bab34f"
          ]
        },
        "id": "2yUCsl8hTC2A",
        "outputId": "a35d0d31-17ab-4248-ff64-0bf4f434307e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cfbdf0a255b4bd0b0e0b4462e33f18d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "967373b240ab4b138aaf8c3c41acbbce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a464bde29228401d84a9fa2a5d91837d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data Collator"
      ],
      "metadata": {
        "id": "-WRyoOrzUs15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=pegagus_tokenizer,\n",
        "                                       model=pegasus_model,\n",
        "                                       label_pad_token_id=-100 # Don't penalize model for not predicting padding\n",
        "                                       )"
      ],
      "metadata": {
        "id": "Zd4YHTNOUt-6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set hyper-parameters"
      ],
      "metadata": {
        "id": "xZGRDgccUzla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 1 # Because model is big\n",
        "logging_steps = 10\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(output_dir=\"pegasus-finetuned-samsum\",\n",
        "                                  num_train_epochs=1,\n",
        "                                  warmup_steps=500,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  eval_strategy=\"epoch\",\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  gradient_accumulation_steps=16, # Make smaller batches & aggregate gradients (saves GPU memory)\n",
        "                                  disable_tqdm=False,\n",
        "                                  report_to=\"none\", # Disable WandB logging\n",
        "                                  predict_with_generate=True, # Evaluate generations as part of training loop\n",
        "                                  generation_max_length=128,\n",
        "                                  fp16=True, # Use mixed precision for faster training on GPU\n",
        "                                  generation_num_beams=1 # Reduce decoder overhead\n",
        "                                  )"
      ],
      "metadata": {
        "id": "nDAXaIRoU06h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "0XGHdmqpUynu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=pegasus_model,\n",
        "                  args=training_args,\n",
        "                  data_collator=data_collator,\n",
        "                  train_dataset=samsum_dataset[\"train\"],\n",
        "                  eval_dataset=samsum_dataset[\"validation\"])\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "lOtSbQCFWSE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f935ab12-dec4-4d3b-c88e-786f50a015fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [920/920 49:14, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.579800</td>\n",
              "      <td>1.424514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3353: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=920, training_loss=1.8299917946691098, metrics={'train_runtime': 2960.9582, 'train_samples_per_second': 4.975, 'train_steps_per_second': 0.311, 'total_flos': 5528248038285312.0, 'train_loss': 1.8299917946691098, 'epoch': 0.9991854466467553})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload model to Hugging Face Hub"
      ],
      "metadata": {
        "id": "cvtnIB6c4f1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login() # Login to account"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "674f59fa5f294944b0afe79abe107a19",
            "9b4afeca739d4c548a2620f88901af71",
            "922b1d5589754967820719b51665360a",
            "46a49f4d92684b3090691ea287961b3e",
            "3d38bec0cee9431b8ce1005e21660687",
            "5b27f222d8034103b9fec5ba516dcfef",
            "21d64fe493584d1d9817af95b30f812c",
            "aae89d23eaf5484a9ba1f194717fbf76",
            "926eb3a5c2154244a0d7a9f64c4d32d5",
            "5941013de19745e8ae620a7228342179",
            "fc37d7cd4e4b4b408c1638e87b9cd03f",
            "1ebec1f91e714168a99dda00194ffdfc",
            "af4500c5be8a4861b74f780c7a9896f0",
            "b58241914025409d8e4933b6e7514020",
            "04e1aa28a0cb4f10a222093ce5a6b01f",
            "55fdc6fba9bc424b98c2af661056be91",
            "826f0543916b48949cadd309505fd255",
            "bcecdad14fdb46a48e2182da55ddae12",
            "e77e0d2a103647ff933c4b712f76b47b",
            "64738585f43b4994bac6dbe03eeeec7c"
          ]
        },
        "id": "7SYzKqYe4jIn",
        "outputId": "576caf82-98db-4eab-c59f-54c092f69c38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "674f59fa5f294944b0afe79abe107a19"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"samsum\",\n",
        "    \"dataset\": \"samsum\",\n",
        "    \"model_name\": \"pegasus-finetuned-samsum\",\n",
        "    \"finetuned_from\": \"google/pegasus-cnn_dailymail\",\n",
        "    \"tasks\": \"summarization\"\n",
        "}\n",
        "\n",
        "trainer.push_to_hub(commit_message=\"Train summarization model\", **kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "222d8299d3884a229ce8b6d26c551121",
            "b7893576a0e8466ab0467b45195e47a3",
            "89db5da1a4db4872acf00586c81f471a",
            "9064f2ee74c8496eb8b7908400201f05",
            "c2d6e588f5574beca64dd192b91bc463",
            "622d8866d3ce4a1b91a800f35b6bb3c6",
            "0ae16333b66a49b392e8c9a289620501",
            "afbf08ef15a64338ae2b27e2c3f709f0",
            "f96e2567a97d4012a9c0df971110ea90",
            "8507f461a69b47e0a2b13a41bbaf57da",
            "fd66d053ade345b5b2a75497e9d7f0f1",
            "e05b9a2d822a4e079e85d2ab400b7b3a",
            "223977e1a4cb407e92aef2371e0b8061",
            "d6468b63ad29441bbd686d8398a38770",
            "ca456145f8cc4e8982ba809a260c7806",
            "b3292cf7c6324216b8a10ca4ab3d7edd",
            "209839908eba40af885a25b07061b489",
            "922e273f05914cd9824a690719bde4f8",
            "1610a286868f4dd99e22336edd3ae533",
            "7e625ab7a7b242beb69425727a641731",
            "9f801720ee494021a77b977ca546443e",
            "47c31c8eb96f49b6941c63d7394ba54a",
            "5b8f44718d2d4d70b0356d04d3412c9d",
            "380139ef6ecf4536ac1914dca898f09f",
            "6260ec713df945569514c9051a184b9f",
            "fb04095edd334d0b9c1b36124cb14d4d",
            "3ffb06efb6e7433180029cd76c3b406a",
            "e4be86a0d36a472fb5d9a266c166fdd3",
            "344b6ea6f24d433b85d720c16dae9b6a",
            "4c22a2b114324a1296cc0c72090eb962",
            "68f739da3ad6479684b3ca922c7337c0",
            "f98e5b5234744528ba8418c163f1c8d3",
            "cddd69119e6b42ab84f2e1ebb6231d03",
            "fce8427247a24495b6138cab15a3697b",
            "b5635c255ef24ead9a81452de91659d5",
            "503e4b0aab4546a58234ec47b9bdc15c",
            "906c78a780f1407e91bac6078ea20ea2",
            "3d822616653040fcad97eca960e01bd4",
            "c9a34eb10e7e4b289f5b7515dc3ca147",
            "e4568026670b43f9a284dd2e8eeca815",
            "25968f203e8b404cac164370d34f4dc8",
            "5be996e1a3c74f169ca61240eb58c63a",
            "570771d7313a4c448eb98c751dc9f2cf",
            "4e794dea657f413aac32dc152da6c643"
          ]
        },
        "id": "Mwk5PFiS4mdy",
        "outputId": "a1232884-0c35-4392-f2a3-219190a111af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/5.50k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "222d8299d3884a229ce8b6d26c551121"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e05b9a2d822a4e079e85d2ab400b7b3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b8f44718d2d4d70b0356d04d3412c9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fce8427247a24495b6138cab15a3697b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/avanishd/pegasus-finetuned-samsum/commit/d42943458017c724e090e9f210e757c13de22292', commit_message='Train summarization model', commit_description='', oid='d42943458017c724e090e9f210e757c13de22292', pr_url=None, repo_url=RepoUrl('https://huggingface.co/avanishd/pegasus-finetuned-samsum', endpoint='https://huggingface.co', repo_type='model', repo_id='avanishd/pegasus-finetuned-samsum'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
